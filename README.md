# Leveraging LLMs for K-12 Education Assessment: An Open-Ended Question Answering Use Case
Repository of the article "Leveraging LLMs for K-12 Education Assessment: An Open-Ended Question Answering Use Case" presented at the IEEE URUCON 2024 conference.

The repository includes:
* the prompts used to generate the responses corresponding to the different gradings: excellent, acceptable and incorrect (prompt_dataset.txt).
* the different prompts tested with several LLMs ([prompts_URUCON.txt](https://github.com/gcapde/eval_llms_edutech_assessment/blob/main/prompts_URUCON.txt) and [inverted_prompts_URUCON.txt](https://github.com/gcapde/eval_llms_edutech_assessment/blob/main/inverted_prompts_URUCON.txt)).
* the configuration files used to run the tests with promptfoo ([promptfooconfig_URUCON.yml](https://github.com/gcapde/eval_llms_edutech_assessment/blob/main/promptfooconfig_URUCON.yml)).
* the python code used to generate the graphs included in the paper (result_analysis.py).
